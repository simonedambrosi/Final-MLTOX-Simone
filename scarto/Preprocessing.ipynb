{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Sun Jan 31 20:16:05 2021\n",
      "Loading raw data\n",
      "tests table loaded!\n",
      "species table loaded!\n",
      "results table loaded!\n",
      "Tests table dimensions:  (681605, 122)\n",
      "Species table dimensions:  (27125, 15)\n",
      "Results table dimensions:  (1006972, 137)\n",
      "Prefiltering Step... Sun Jan 31 20:17:47 2021\n",
      "Dimensions after prefiltering step:  (64341, 272)\n",
      "Selection and Imputation Step... Sun Jan 31 20:17:56 2021\n",
      "Features:\n",
      "obs_duration_mean, obs_duration_unit, endpoint, effect, measurement, conc1_type, conc1_mean, conc1_unit, test_cas, test_location, exposure_type, control_type, media_type, application_freq_unit, class, tax_order, family, genus, species, \n",
      "Dimension after imputation step: (50160, 16)\n",
      "Aggregation of repeated experiments Sun Jan 31 20:17:57 2021\n",
      "Dimension after repeated experiments aggregation: (28815, 14)\n",
      "Remark: Stable internet connection required for smiles and pubchem extraction!\n",
      "Smiles extraction... Sun Jan 31 20:17:57 2021\n",
      "Pubchem2d extraction... Sun Jan 31 20:45:33 2021\n",
      "Molecular Descriptors extraction... Sun Jan 31 21:44:35 2021\n",
      "Finding atom number...\n",
      "Finding number of alone atoms...\n",
      "Finding single bounds number...\n",
      "Finding double bounds number...\n",
      "Finding triple bounds number...\n",
      "Finding ring number...\n",
      "Finding Molecular Weight...\n",
      "Finding morgan density...\n",
      "Finding partition number (LogP)...\n",
      "Finding number of OH group...\n",
      "Finding Melting Point and Water Solubility using CompTox Database...\n",
      "Loading and merging CompTox Database... Sun Jan 31 21:44:39 2021\n",
      "End Molecular Descriptors extraction! Sun Jan 31 21:51:06 2021\n",
      "Cleaning Chemical data... Sun Jan 31 21:51:06 2021\n",
      "The extracted chemicals are: 2199\n",
      "Merging chemical descriptors with experiments\n",
      "Dimension of final dataset: 20128 experiments and 28 features\n",
      "Final features: ['test_cas', 'obs_duration_mean', 'conc1_type', 'fish', 'exposure_type', 'control_type', 'media_type', 'application_freq_unit', 'conc1_mean', 'class', 'tax_order', 'family', 'genus', 'species', 'smiles', 'pubchem2d', 'atom_number', 'alone_atom_number', 'bonds_number', 'doubleBond', 'tripleBond', 'ring_number', 'Mol', 'MorganDensity', 'LogP', 'oh_count', 'MeltingPoint', 'WaterSolubility']\n"
     ]
    }
   ],
   "source": [
    "from helper_preprocessing import *\n",
    "\n",
    "path_tests = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/tests.txt'\n",
    "path_species = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/species.txt'\n",
    "path_results = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/results.txt'\n",
    "\n",
    "\n",
    "tests, species, results = load_raw_data(path_tests, path_results, path_species)\n",
    "\n",
    "prefiltered_data = prefilter(species, tests, results)\n",
    "\n",
    "del tests, species, results\n",
    "\n",
    "db = select_impute_features(prefiltered_data)\n",
    "db = repeated_experiments(db)\n",
    "db['test_cas'] = db.test_cas.apply(to_cas)\n",
    "\n",
    "db.to_csv('repeated_experiments.csv')\n",
    "\n",
    "chemicals = extract_chemical_data(db)\n",
    "\n",
    "print('Cleaning Chemical data...', ctime())\n",
    "chemicals = process_smiles_features(chemicals)\n",
    "\n",
    "print('The extracted chemicals are:', chemicals.shape[0])\n",
    "\n",
    "chemicals.to_csv('chemicals.csv')\n",
    "\n",
    "print('Merging chemical descriptors with experiments')\n",
    "final_db = db.merge(chemicals, right_on = 'test_cas', left_on = 'test_cas')\n",
    "\n",
    "print('Dimension of final dataset:', final_db.shape[0], 'experiments and', final_db.shape[1], 'features')\n",
    "print('Final features:', [i for i in final_db.columns])\n",
    "\n",
    "final_db.to_csv('lc_db_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start! Thu Apr 29 19:28:15 2021\n",
      "Loading raw data\n",
      "tests table loaded!\n",
      "species table loaded!\n",
      "results table loaded!\n",
      "Tests table dimensions:  (681605, 122)\n",
      "Species table dimensions:  (27125, 15)\n",
      "Results table dimensions:  (1006972, 137)\n",
      "Prefiltering Step... Thu Apr 29 19:29:59 2021\n",
      "Dimensions after prefiltering step:  (64341, 272)\n"
     ]
    }
   ],
   "source": [
    "from helper_preprocessing import *\n",
    "\n",
    "path_tests = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/tests.txt'\n",
    "path_species = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/species.txt'\n",
    "path_results = 'C:/Users/Simone/Desktop/Utilità tesi magistrale/data/results.txt'\n",
    "\n",
    "\n",
    "tests, species, results = load_raw_data(path_tests, path_results, path_species)\n",
    "\n",
    "prefiltered_data = prefilter(species, tests, results)\n",
    "\n",
    "del tests, species, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = ['obs_duration_mean', 'obs_duration_unit',\n",
    "       'endpoint', 'effect', 'measurement', 'conc1_type', 'conc1_mean',\n",
    "       'conc1_unit', 'test_cas', 'test_location', 'exposure_type',\n",
    "       'control_type', 'media_type', 'application_freq_unit', 'class',\n",
    "       'tax_order', 'family', 'genus', 'species']\n",
    "    \n",
    "db = prefiltered_data.copy()\n",
    "db = db[keep_columns]\n",
    "\n",
    "del prefiltered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ug/L       38076\n",
       "mg/L        8758\n",
       "ppm         5336\n",
       "AI ug/L     4598\n",
       "AI mg/L     2680\n",
       "ppb         1423\n",
       "ul/L        1204\n",
       "AI ppm       319\n",
       "uM           309\n",
       "AI ng/L      234\n",
       "AI ppb       228\n",
       "%            162\n",
       "mg/dm3       139\n",
       "ml/L         134\n",
       "umol/L       128\n",
       "Name: conc1_unit, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.conc1_unit.value_counts()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_conc(results_prefiltered):\n",
    "    \n",
    "    db = results_prefiltered.copy()\n",
    "    \n",
    "    to_drop_conc_mean = db[db.conc1_mean == 'NR'].index\n",
    "    db_filtered_mean = db.drop(index = to_drop_conc_mean).copy()\n",
    "\n",
    "    db_filtered_mean.loc[:,'conc1_mean'] = db_filtered_mean.conc1_mean\\\n",
    "                                                        .apply(lambda x: x.replace(\"*\", \"\") if \"*\" in x else x).copy()\n",
    "\n",
    "    to_drop_invalid_conc = db_filtered_mean[db_filtered_mean.conc1_mean == '>100000'].index\n",
    "    db_filtered_mean.drop(index = to_drop_invalid_conc, inplace = True)\n",
    "\n",
    "    db_filtered_mean.loc[:,'conc1_mean'] = db_filtered_mean.conc1_mean.astype(float).copy()\n",
    "\n",
    "    to_drop_useless = db_filtered_mean[db_filtered_mean.conc1_mean == 0].index\n",
    "    db_filtered_mean.drop(index = to_drop_useless, inplace = True)\n",
    "\n",
    "    db_filtered_mean.loc[:,'conc1_unit'] = db_filtered_mean.conc1_unit\\\n",
    "                                                        .apply(lambda x: x.replace(\"AI \", \"\") if 'AI' in x else x)\n",
    "    \n",
    "    db_filtered_mean.loc[(db_filtered_mean.conc1_unit == 'ppb') | (db_filtered_mean.conc1_unit == 'ug/L'), 'conc1_mean'] = \\\n",
    "                db_filtered_mean.conc1_mean[(db_filtered_mean.conc1_unit == 'ppb') | (db_filtered_mean.conc1_unit == 'ug/L')]/1000\n",
    "    \n",
    "    db_filtered_mean.loc[db_filtered_mean.conc1_unit == 'ng/L', 'conc1_mean'] = db_filtered_mean.conc1_mean[db_filtered_mean.conc1_unit == 'ng/L']*(10**(-6))\n",
    "\n",
    "    to_drop_unit = db_filtered_mean.loc[(db_filtered_mean.conc1_unit == 'uM') | (db_filtered_mean.conc1_unit == 'ul/L')].index\n",
    "    db_filtered_mean.drop(index = to_drop_unit, inplace = True)\n",
    "\n",
    "    to_drop_type = db_filtered_mean.loc[(db_filtered_mean.conc1_type == 'NC') |(db_filtered_mean.conc1_type == 'NR')].index\n",
    "    db_filtered_mean.drop(index = to_drop_type, inplace = True)\n",
    "    \n",
    "    return db_filtered_mean\n",
    "\n",
    "db = impute_conc(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont = db.conc1_unit.value_counts()\n",
    "# cont\n",
    "sum(cont[~cont.index.isin(['mg/L', 'ppb', 'ppm', 'ug/L', 'ng/L'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58438, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
